export const benchmarksData = [{"name": "ClockBench", "description": "Clock benchmark - time-based reasoning tasks", "category": "community", "tags": ["time", "analog", "clock", "reasoning"], "function_name": "clockbench", "is_alpha": false}, {"name": "DetailBench", "description": "Tests whether LLMs notify users about wrong facts in a text while they are tasked to translate said text", "category": "community", "tags": ["knowledge", "graded", "instruction-following"], "function_name": "detailbench", "is_alpha": false}, {"name": "TUMLU", "description": "TUMLU is a comprehensive, multilingual, and natively developed language understanding benchmark specifically designed for Turkic languages.", "category": "community", "tags": ["factuality", "question-answering", "multiple-choice", "reasoning"], "function_name": "tumlu", "is_alpha": false}, {"name": "BoolQ", "description": "BoolQ: A Question Answering Dataset for Boolean Reasoning", "category": "core", "tags": ["boolean-reasoning", "question-answering"], "function_name": "boolq", "is_alpha": false}, {"name": "BrowseComp", "description": "A Simple Yet Challenging Benchmark for Browsing Agents - evaluates model performance on browsing-related tasks", "category": "core", "tags": ["browsing", "web", "reasoning", "graded"], "function_name": "browsecomp", "is_alpha": false}, {"name": "DROP", "description": "Reading comprehension benchmark requiring discrete reasoning over paragraphs (arithmetic, counting, sorting)", "category": "core", "tags": ["reading-comprehension", "reasoning", "arithmetic", "counting", "sorting"], "function_name": "drop", "is_alpha": false}, {"name": "GMCQ", "description": "GitHub Multiple Choice Questions", "category": "core", "tags": ["code-understanding"], "function_name": "rootly_gmcq", "is_alpha": false}, {"name": "GPQA Diamond", "description": "Graduate-level Google-Proof Q&A in biology, chemistry, and physics", "category": "core", "tags": ["multiple-choice", "science", "graduate-level"], "function_name": "gpqa_diamond", "is_alpha": false}, {"name": "GraphWalks", "description": "Multi-hop reasoning on graphs - both BFS and parent finding tasks", "category": "core", "tags": ["long-context", "graphs", "reasoning", "alpha"], "function_name": "graphwalks", "is_alpha": true}, {"name": "GraphWalks BFS", "description": "Multi-hop reasoning on graphs - BFS traversal tasks only", "category": "core", "tags": ["long-context", "graphs", "reasoning", "bfs", "alpha"], "function_name": "graphwalks_bfs", "is_alpha": true}, {"name": "GraphWalks Parents", "description": "Multi-hop reasoning on graphs - parent finding tasks only", "category": "core", "tags": ["long-context", "graphs", "reasoning", "parents", "alpha"], "function_name": "graphwalks_parents", "is_alpha": true}, {"name": "HealthBench", "description": "Medical dialogue evaluation using physician-created rubrics for assessing healthcare conversations", "category": "core", "tags": ["medical", "dialogue", "graded", "rubric-based"], "function_name": "healthbench", "is_alpha": false}, {"name": "HealthBench Consensus", "description": "Medical dialogue cases with strong physician consensus on appropriate responses", "category": "core", "tags": ["medical", "dialogue", "graded", "rubric-based", "consensus"], "function_name": "healthbench_consensus", "is_alpha": false}, {"name": "HealthBench Hard", "description": "Most challenging medical dialogue cases from HealthBench requiring nuanced medical knowledge", "category": "core", "tags": ["medical", "dialogue", "graded", "rubric-based", "hard"], "function_name": "healthbench_hard", "is_alpha": false}, {"name": "HumanEval", "description": "Code generation benchmark with 164 programming problems", "category": "core", "tags": ["coding", "generation", "execution"], "function_name": "humaneval", "is_alpha": false}, {"name": "Humanity's Last Exam", "description": "Multi-modal benchmark at the frontier of human knowledge - 2,500 questions across mathematics, humanities, and natural sciences designed by subject-matter experts globally", "category": "core", "tags": ["knowledge", "reasoning", "multi-modal", "graded", "frontier"], "function_name": "hle", "is_alpha": false}, {"name": "Humanity's Last Exam (Text-Only)", "description": "Text-only variant of HLE with multi-modal questions filtered out - evaluates models without vision capabilities on text-based questions from the frontier of human knowledge", "category": "core", "tags": ["knowledge", "reasoning", "text-only", "graded", "frontier"], "function_name": "hle_text", "is_alpha": false}, {"name": "JSONSchemaBench", "description": "JSON Schema generation benchmark with ~10K real-world schemas from GitHub, Kubernetes, and other sources for evaluating constrained decoding", "category": "core", "tags": ["json", "jsonschema", "generation", "constrained-decoding"], "function_name": "jsonschemabench", "is_alpha": false}, {"name": "MATH", "description": "Measuring Mathematical Problem Solving - 5000 competition math problems across 7 subjects and 5 difficulty levels", "category": "core", "tags": ["math", "problem-solving", "reasoning", "competition", "graded"], "function_name": "math", "is_alpha": false}, {"name": "MATH-500", "description": "500-problem subset of MATH dataset for faster evaluation of mathematical problem solving", "category": "core", "tags": ["math", "problem-solving", "reasoning", "competition", "graded", "subset"], "function_name": "math_500", "is_alpha": false}, {"name": "MBPP", "description": "Mostly Basic Python Problems â€” code generation tasks with unit test verification", "category": "core", "tags": ["code", "generation", "sandbox", "reasoning"], "function_name": "mbpp", "is_alpha": false}, {"name": "MGSM", "description": "Multilingual Grade School Math benchmark across 11 languages for testing mathematical reasoning", "category": "core", "tags": ["math", "multilingual", "reasoning", "chain-of-thought"], "function_name": "mgsm", "is_alpha": false}, {"name": "MGSM English", "description": "Grade school math problems in English for testing mathematical reasoning", "category": "core", "tags": ["math", "english", "reasoning", "chain-of-thought"], "function_name": "mgsm_en", "is_alpha": false}, {"name": "MGSM Latin Script", "description": "Grade school math problems in Latin script languages (German, English, Spanish, French, Swahili)", "category": "core", "tags": ["math", "multilingual", "latin-script", "reasoning", "chain-of-thought"], "function_name": "mgsm_latin", "is_alpha": false}, {"name": "MGSM Non-Latin Script", "description": "Grade school math problems in non-Latin script languages (Bengali, Japanese, Russian, Telugu, Thai, Chinese)", "category": "core", "tags": ["math", "multilingual", "non-latin-script", "reasoning", "chain-of-thought"], "function_name": "mgsm_non_latin", "is_alpha": false}, {"name": "MMLU (cais/mmlu)", "description": "Massive Multitask Language Understanding - 57 academic subjects from the cais/mmlu dataset", "category": "core", "tags": ["multiple-choice", "knowledge", "reasoning", "multitask"], "function_name": "mmlu", "is_alpha": false}, {"name": "MMLU Pro (TIGER-Lab)", "description": "Enhanced version of MMLU with more challenging, reasoning-focused questions.", "category": "core", "tags": ["multiple-choice", "knowledge", "reasoning", "multitask"], "function_name": "mmlu_pro", "is_alpha": false}, {"name": "MMMU", "description": "Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark with 11.5K questions across 30 subjects from college exams, quizzes, and textbooks", "category": "core", "tags": ["multimodal", "multiple-choice", "reasoning", "college-level", "images"], "function_name": "mmmu", "is_alpha": false}, {"name": "MMMU Accounting", "description": "MMMU Accounting subset focusing on accounting principles and practices", "category": "core", "tags": ["multimodal", "multiple-choice", "accounting", "business", "images"], "function_name": "mmmu_accounting", "is_alpha": false}, {"name": "MMMU Agriculture", "description": "MMMU Agriculture subset focusing on agricultural sciences and practices", "category": "core", "tags": ["multimodal", "multiple-choice", "agriculture", "science", "images"], "function_name": "mmmu_agriculture", "is_alpha": false}, {"name": "MMMU Architecture and Engineering", "description": "MMMU Architecture and Engineering subset focusing on engineering design and architecture", "category": "core", "tags": ["multimodal", "multiple-choice", "architecture", "engineering", "design", "images"], "function_name": "mmmu_architecture_and_engineering", "is_alpha": false}, {"name": "MMMU Art", "description": "MMMU Art subset focusing on art and visual design questions", "category": "core", "tags": ["multimodal", "multiple-choice", "art", "visual-design", "images"], "function_name": "mmmu_art", "is_alpha": false}, {"name": "MMMU Art Theory", "description": "MMMU Art Theory subset focusing on art history and theoretical concepts", "category": "core", "tags": ["multimodal", "multiple-choice", "art", "theory", "history", "images"], "function_name": "mmmu_art_theory", "is_alpha": false}, {"name": "MMMU Basic Medical Science", "description": "MMMU Basic Medical Science subset focusing on fundamental medical knowledge", "category": "core", "tags": ["multimodal", "multiple-choice", "medicine", "science", "health", "images"], "function_name": "mmmu_basic_medical_science", "is_alpha": false}, {"name": "MMMU Biology", "description": "MMMU Biology subset focusing on biological sciences", "category": "core", "tags": ["multimodal", "multiple-choice", "biology", "science", "images"], "function_name": "mmmu_biology", "is_alpha": false}, {"name": "MMMU Chemistry", "description": "MMMU Chemistry subset focusing on chemical sciences", "category": "core", "tags": ["multimodal", "multiple-choice", "chemistry", "science", "images"], "function_name": "mmmu_chemistry", "is_alpha": false}, {"name": "MMMU Clinical Medicine", "description": "MMMU Clinical Medicine subset focusing on clinical medical practice", "category": "core", "tags": ["multimodal", "multiple-choice", "medicine", "clinical", "health", "images"], "function_name": "mmmu_clinical_medicine", "is_alpha": false}, {"name": "MMMU Design", "description": "MMMU Design subset focusing on design principles and practices", "category": "core", "tags": ["multimodal", "multiple-choice", "design", "visual", "creative", "images"], "function_name": "mmmu_design", "is_alpha": false}, {"name": "MMMU Diagnostics and Laboratory Medicine", "description": "MMMU Diagnostics and Laboratory Medicine subset focusing on medical diagnostics", "category": "core", "tags": ["multimodal", "multiple-choice", "medicine", "diagnostics", "laboratory", "images"], "function_name": "mmmu_diagnostics_and_laboratory_medicine", "is_alpha": false}, {"name": "MMMU Electronics", "description": "MMMU Electronics subset focusing on electronic systems and circuits", "category": "core", "tags": ["multimodal", "multiple-choice", "electronics", "engineering", "technology", "images"], "function_name": "mmmu_electronics", "is_alpha": false}, {"name": "MMMU Energy and Power", "description": "MMMU Energy and Power subset focusing on energy systems and power generation", "category": "core", "tags": ["multimodal", "multiple-choice", "energy", "power", "engineering", "images"], "function_name": "mmmu_energy_and_power", "is_alpha": false}, {"name": "MMMU Finance", "description": "MMMU Finance subset focusing on financial concepts and analysis", "category": "core", "tags": ["multimodal", "multiple-choice", "finance", "business", "economics", "images"], "function_name": "mmmu_finance", "is_alpha": false}, {"name": "MMMU Geography", "description": "MMMU Geography subset focusing on geographical knowledge and analysis", "category": "core", "tags": ["multimodal", "multiple-choice", "geography", "earth-science", "spatial", "images"], "function_name": "mmmu_geography", "is_alpha": false}, {"name": "MMMU History", "description": "MMMU History subset focusing on historical knowledge and analysis", "category": "core", "tags": ["multimodal", "multiple-choice", "history", "humanities", "culture", "images"], "function_name": "mmmu_history", "is_alpha": false}, {"name": "MMMU Literature", "description": "MMMU Literature subset focusing on literary analysis and knowledge", "category": "core", "tags": ["multimodal", "multiple-choice", "literature", "humanities", "language", "images"], "function_name": "mmmu_literature", "is_alpha": false}, {"name": "MMMU MCQ", "description": "MMMU MCQ subset focusing on multiple choice questions", "category": "core", "tags": ["multimodal", "multiple-choice", "images"], "function_name": "mmmu_mcq", "is_alpha": false}, {"name": "MMMU Management", "description": "MMMU Management subset focusing on management principles and practices", "category": "core", "tags": ["multimodal", "multiple-choice", "management", "business", "leadership", "images"], "function_name": "mmmu_manage", "is_alpha": false}, {"name": "MMMU Marketing", "description": "MMMU Marketing subset focusing on marketing strategies and concepts", "category": "core", "tags": ["multimodal", "multiple-choice", "marketing", "business", "communication", "images"], "function_name": "mmmu_marketing", "is_alpha": false}, {"name": "MMMU Materials", "description": "MMMU Materials subset focusing on materials science and engineering", "category": "core", "tags": ["multimodal", "multiple-choice", "materials", "science", "engineering", "images"], "function_name": "mmmu_materials", "is_alpha": false}, {"name": "MMMU Mechanical Engineering", "description": "MMMU Mechanical Engineering subset focusing on mechanical systems and design", "category": "core", "tags": ["multimodal", "multiple-choice", "mechanical", "engineering", "design", "images"], "function_name": "mmmu_mechanical_engineering", "is_alpha": false}, {"name": "MMMU Music", "description": "MMMU Music subset focusing on music theory and analysis", "category": "core", "tags": ["multimodal", "multiple-choice", "music", "arts", "theory", "images"], "function_name": "mmmu_music", "is_alpha": false}, {"name": "MMMU Open", "description": "MMMU Open subset focusing on open-ended questions", "category": "core", "tags": ["multimodal", "open-ended", "images"], "function_name": "mmmu_open", "is_alpha": false}, {"name": "MMMU Pharmacy", "description": "MMMU Pharmacy subset focusing on pharmaceutical sciences and practice", "category": "core", "tags": ["multimodal", "multiple-choice", "pharmacy", "medicine", "health", "images"], "function_name": "mmmu_pharmacy", "is_alpha": false}, {"name": "MMMU Physics", "description": "MMMU Physics subset focusing on physics and physical sciences", "category": "core", "tags": ["multimodal", "multiple-choice", "physics", "science", "images"], "function_name": "mmmu_physics", "is_alpha": false}, {"name": "MMMU Public Health", "description": "MMMU Public Health subset focusing on public health concepts and practices", "category": "core", "tags": ["multimodal", "multiple-choice", "public-health", "health", "population", "images"], "function_name": "mmmu_public_health", "is_alpha": false}, {"name": "MMMU Sociology", "description": "MMMU Sociology subset focusing on sociological concepts and analysis", "category": "core", "tags": ["multimodal", "multiple-choice", "sociology", "social-science", "society", "images"], "function_name": "mmmu_sociology", "is_alpha": false}, {"name": "MMMU-Pro", "description": "Enhanced multimodal MMMU-Pro benchmark with multiple-choice across many options and images", "category": "core", "tags": ["multimodal", "multiple-choice", "reasoning", "images", "mmmu-pro"], "function_name": "mmmu_pro", "is_alpha": false}, {"name": "MMMU-Pro (Vision)", "description": "MMMU-Pro vision subset with images and multiple-choice questions", "category": "core", "tags": ["multimodal", "vision", "multiple-choice", "images", "mmmu-pro"], "function_name": "mmmu_pro_vision", "is_alpha": false}, {"name": "MMStar", "description": "MMStar benchmark for measuring multi-modal gain and leakage via coordinated vision and text ablations", "category": "core", "tags": ["vision", "multi-modal", "leakage", "perception", "reasoning"], "function_name": "mmstar", "is_alpha": false}, {"name": "MuSR", "description": "Testing the Limits of Chain-of-thought with Multistep Soft Reasoning - includes murder mysteries, object placements, and team allocation tasks", "category": "core", "tags": ["multiple-choice", "reasoning", "commonsense", "chain-of-thought"], "function_name": "musr", "is_alpha": false}, {"name": "MuSR Murder Mysteries", "description": "MuSR murder mystery scenarios - who is the most likely murderer?", "category": "core", "tags": ["multiple-choice", "reasoning", "commonsense", "chain-of-thought", "murder-mysteries"], "function_name": "musr_murder_mysteries", "is_alpha": false}, {"name": "MuSR Object Placements", "description": "MuSR object placement reasoning - where would someone look for an object?", "category": "core", "tags": ["multiple-choice", "reasoning", "commonsense", "chain-of-thought", "object-placements"], "function_name": "musr_object_placements", "is_alpha": false}, {"name": "MuSR Team Allocation", "description": "MuSR team allocation problems - how to allocate people to tasks efficiently?", "category": "core", "tags": ["multiple-choice", "reasoning", "commonsense", "chain-of-thought", "team-allocation"], "function_name": "musr_team_allocation", "is_alpha": false}, {"name": "OpenAI MRCR (2 Needles)", "description": "Memory-Recall with Contextual Retrieval - long-context evaluation that measures recall of 2 needles across million-token contexts", "category": "core", "tags": ["long-context", "retrieval", "needle", "sequence-matching"], "function_name": "openai_mrcr_2n", "is_alpha": false}, {"name": "OpenAI MRCR (4 Needles)", "description": "Memory-Recall with Contextual Retrieval - long-context evaluation that measures recall of 4 needles across million-token contexts", "category": "core", "tags": ["long-context", "retrieval", "needle", "sequence-matching"], "function_name": "openai_mrcr_4n", "is_alpha": false}, {"name": "OpenAI MRCR (8 Needles)", "description": "Memory-Recall with Contextual Retrieval - long-context evaluation that measures recall of 8 needles across million-token contexts", "category": "core", "tags": ["long-context", "retrieval", "needle", "sequence-matching"], "function_name": "openai_mrcr_8n", "is_alpha": false}, {"name": "OpenAI MRCR (Full)", "description": "Memory-Recall with Contextual Retrieval - long-context evaluation that measures recall of 2, 4, and 8 needles across million-token contexts", "category": "core", "tags": ["long-context", "retrieval", "needle", "sequence-matching"], "function_name": "openai_mrcr", "is_alpha": false}, {"name": "OpenBookQA", "description": "Elementary-level science questions probing understanding of core facts", "category": "core", "tags": ["multiple-choice", "science", "elementary", "open-book"], "function_name": "openbookqa", "is_alpha": false}, {"name": "SciCode", "description": "Scientific computing and programming challenges", "category": "core", "tags": ["code-generation", "science", "alpha"], "function_name": "scicode", "is_alpha": true}, {"name": "SimpleQA", "description": "Measuring short-form factuality in large language models with simple Q&A pairs", "category": "core", "tags": ["factuality", "question-answering", "graded"], "function_name": "simpleqa", "is_alpha": false}, {"name": "SuperGPQA", "description": "Scaling LLM Evaluation across 285 Graduate Disciplines - 26,529 multiple-choice questions across science, engineering, medicine, economics, and philosophy", "category": "core", "tags": ["multiple-choice", "knowledge", "graduate-level", "multidisciplinary"], "function_name": "supergpqa", "is_alpha": false}, {"name": "CTI-Bench ATE", "description": "Extracting MITRE ATT&CK techniques from malware and threat descriptions", "category": "cybersecurity", "tags": ["extraction", "cybersecurity"], "function_name": "cti_bench_ate", "is_alpha": false}, {"name": "CTI-Bench MCQ", "description": "Multiple-choice questions evaluating understanding of CTI standards, threats, detection strategies, and best practices using authoritative sources like NIST and MITRE", "category": "cybersecurity", "tags": ["multiple-choice", "cybersecurity", "knowledge"], "function_name": "cti_bench_mcq", "is_alpha": false}, {"name": "CTI-Bench RCM", "description": "Mapping CVE descriptions to CWE categories to evaluate vulnerability classification ability", "category": "cybersecurity", "tags": ["classification", "cybersecurity"], "function_name": "cti_bench_rcm", "is_alpha": false}, {"name": "CTI-Bench VSP", "description": "Calculating CVSS scores from vulnerability descriptions to assess severity evaluation skills", "category": "cybersecurity", "tags": ["regression", "cybersecurity"], "function_name": "cti_bench_vsp", "is_alpha": false}, {"name": "AIME 2023 I", "description": "American Invitational Mathematics Examination 2023 (First)", "category": "math", "tags": ["math", "competition", "aime", "2023"], "function_name": "aime_2023_I", "is_alpha": false}, {"name": "AIME 2023 II", "description": "American Invitational Mathematics Examination 2023 (Second)", "category": "math", "tags": ["math", "competition", "aime", "2023"], "function_name": "aime_2023_II", "is_alpha": false}, {"name": "AIME 2024", "description": "American Invitational Mathematics Examination 2024 (Combined I & II)", "category": "math", "tags": ["math", "competition", "aime", "2024", "combined"], "function_name": "aime_2024", "is_alpha": false}, {"name": "AIME 2024 I", "description": "American Invitational Mathematics Examination 2024 (First)", "category": "math", "tags": ["math", "competition", "aime", "2024"], "function_name": "aime_2024_I", "is_alpha": false}, {"name": "AIME 2024 II", "description": "American Invitational Mathematics Examination 2024 (Second)", "category": "math", "tags": ["math", "competition", "aime", "2024"], "function_name": "aime_2024_II", "is_alpha": false}, {"name": "AIME 2025", "description": "American Invitational Mathematics Examination 2025", "category": "math", "tags": ["math", "competition", "aime", "2025"], "function_name": "aime_2025", "is_alpha": false}, {"name": "AIME 2025 II", "description": "American Invitational Mathematics Examination 2025 (Second)", "category": "math", "tags": ["math", "competition", "aime", "2025"], "function_name": "aime_2025_II", "is_alpha": false}, {"name": "BRUMO 2025", "description": "Bruno Mathematical Olympiad 2025", "category": "math", "tags": ["math", "competition", "olympiad", "2025"], "function_name": "brumo_2025", "is_alpha": false}, {"name": "HMMT Feb 2023", "description": "Harvard-MIT Mathematics Tournament February 2023", "category": "math", "tags": ["math", "competition", "hmmt", "2023"], "function_name": "hmmt_feb_2023", "is_alpha": false}, {"name": "HMMT Feb 2024", "description": "Harvard-MIT Mathematics Tournament February 2024", "category": "math", "tags": ["math", "competition", "hmmt", "2024"], "function_name": "hmmt_feb_2024", "is_alpha": false}, {"name": "HMMT Feb 2025", "description": "Harvard-MIT Mathematics Tournament February 2025", "category": "math", "tags": ["math", "competition", "hmmt", "2025"], "function_name": "hmmt_feb_2025", "is_alpha": false}, {"name": "MMMU Math", "description": "MMMU Mathematics subset focusing on mathematical reasoning", "category": "math", "tags": ["multimodal", "multiple-choice", "mathematics", "reasoning", "images"], "function_name": "mmmu_math", "is_alpha": false}];
