export const benchmarksData = [
  {
    "name": "AIME 2023 I",
    "description": "American Invitational Mathematics Examination 2023 (First)",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "aime",
      "2023"
    ],
    "function_name": "aime_2023_I",
    "is_alpha": false
  },
  {
    "name": "AIME 2023 II",
    "description": "American Invitational Mathematics Examination 2023 (Second)",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "aime",
      "2023"
    ],
    "function_name": "aime_2023_II",
    "is_alpha": false
  },
  {
    "name": "AIME 2024",
    "description": "American Invitational Mathematics Examination 2024 (Combined I & II)",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "aime",
      "2024",
      "combined"
    ],
    "function_name": "aime_2024",
    "is_alpha": false
  },
  {
    "name": "AIME 2024 I",
    "description": "American Invitational Mathematics Examination 2024 (First)",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "aime",
      "2024"
    ],
    "function_name": "aime_2024_I",
    "is_alpha": false
  },
  {
    "name": "AIME 2024 II",
    "description": "American Invitational Mathematics Examination 2024 (Second)",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "aime",
      "2024"
    ],
    "function_name": "aime_2024_II",
    "is_alpha": false
  },
  {
    "name": "AIME 2025",
    "description": "American Invitational Mathematics Examination 2025",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "aime",
      "2025"
    ],
    "function_name": "aime_2025",
    "is_alpha": false
  },
  {
    "name": "AIME 2025 II",
    "description": "American Invitational Mathematics Examination 2025 (Second)",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "aime",
      "2025"
    ],
    "function_name": "aime_2025_II",
    "is_alpha": false
  },
  {
    "name": "ANLI (All Rounds)",
    "description": "Adversarial Natural Language Inference - challenging NLI benchmark",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "nli",
      "adversarial",
      "reasoning"
    ],
    "function_name": "anli",
    "is_alpha": false
  },
  {
    "name": "ANLI Round 1",
    "description": "Adversarial NLI Round 1",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "nli",
      "adversarial",
      "reasoning"
    ],
    "function_name": "anli_r1",
    "is_alpha": false
  },
  {
    "name": "ANLI Round 2",
    "description": "Adversarial NLI Round 2",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "nli",
      "adversarial",
      "reasoning"
    ],
    "function_name": "anli_r2",
    "is_alpha": false
  },
  {
    "name": "ANLI Round 3",
    "description": "Adversarial NLI Round 3",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "nli",
      "adversarial",
      "reasoning"
    ],
    "function_name": "anli_r3",
    "is_alpha": false
  },
  {
    "name": "ARC-AGI",
    "description": "Abstraction and Reasoning Corpus for Artificial General Intelligence; specify version with -T version=1 or version=2",
    "category": "core",
    "tags": [
      "reasoning",
      "pattern-recognition",
      "abstract-reasoning",
      "visual",
      "logic",
      "agi"
    ],
    "function_name": "arc_agi",
    "is_alpha": false
  },
  {
    "name": "ARC-AGI-1",
    "description": "ARC-AGI dataset version 1",
    "category": "core",
    "tags": [
      "reasoning",
      "pattern-recognition",
      "abstract-reasoning",
      "visual",
      "logic",
      "agi"
    ],
    "function_name": "arc_agi_1",
    "is_alpha": false
  },
  {
    "name": "ARC-AGI-2",
    "description": "ARC-AGI dataset version 2",
    "category": "core",
    "tags": [
      "reasoning",
      "pattern-recognition",
      "abstract-reasoning",
      "visual",
      "logic",
      "agi"
    ],
    "function_name": "arc_agi_2",
    "is_alpha": false
  },
  {
    "is_alpha": false
  },
  {
    "name": "ARC-Challenge",
    "description": "AI2 Reasoning Challenge - Challenging questions from grade-school science exams",
    "category": "core",
    "tags": [
      "multiple-choice",
      "science",
      "commonsense-reasoning"
    ],
    "function_name": "arc_challenge",
    "is_alpha": false
  },
  {
    "name": "ARC-Easy",
    "description": "AI2 Reasoning Challenge - Easy questions from grade-school science exams",
    "category": "core",
    "tags": [
      "multiple-choice",
      "science",
      "commonsense-reasoning"
    ],
    "function_name": "arc_easy",
    "is_alpha": false
  },
  {
    "name": "COPA",
    "description": "Choice of Plausible Alternatives for causal reasoning",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "superglue",
      "nli",
      "reasoning"
    ],
    "function_name": "copa",
    "is_alpha": false
  },
  {
    "name": "CTI-Bench ATE",
    "description": "Extracting MITRE ATT&CK techniques from malware and threat descriptions",
    "category": "cybersecurity",
    "name": "BBH: Causal Judgment",
    "description": "BigBench Hard - Causal judgment reasoning",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought"
    ],
    "function_name": "bbh_causal_judgment",
    "is_alpha": false
  },
  {
    "name": "BBH: Date Understanding",
    "description": "BigBench Hard - Understanding and reasoning about dates",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought"
    ],
    "function_name": "bbh_date_understanding",
    "is_alpha": false
  },
  {
    "name": "BBH: Disambiguation QA",
    "description": "BigBench Hard - Pronoun disambiguation in questions",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought"
    ],
    "function_name": "bbh_disambiguation_qa",
    "is_alpha": false
  },
  {
    "name": "BBH: Geometric Shapes",
    "description": "BigBench Hard - Reasoning about geometric shapes",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "geometry"
    ],
    "function_name": "bbh_geometric_shapes",
    "is_alpha": false
  },
  {
    "name": "BBH: Logical Deduction (3 Objects)",
    "description": "BigBench Hard - Logical deduction with three objects",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "logic"
    ],
    "function_name": "bbh_logical_deduction_three_objects",
    "is_alpha": false
  },
  {
    "name": "CommitmentBank",
    "description": "Natural language inference with commitment",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "superglue",
      "nli",
      "reasoning"
    ],
    "function_name": "cb",
    "is_alpha": false
  },
  {
    "name": "DROP",
    "description": "Reading comprehension benchmark requiring discrete reasoning over paragraphs (arithmetic, counting, sorting)",
    "name": "BBH: Logical Deduction (5 Objects)",
    "description": "BigBench Hard - Logical deduction with five objects",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "logic"
    ],
    "function_name": "bbh_logical_deduction_five_objects",
    "is_alpha": false
  },
  {
    "name": "BBH: Logical Deduction (7 Objects)",
    "description": "BigBench Hard - Logical deduction with seven objects",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "logic"
    ],
    "function_name": "bbh_logical_deduction_seven_objects",
    "is_alpha": false
  },
  {
    "name": "BBH: Movie Recommendation",
    "description": "BigBench Hard - Movie recommendation reasoning",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought"
    ],
    "function_name": "bbh_movie_recommendation",
    "is_alpha": false
  },
  {
    "name": "BBH: Navigate",
    "description": "BigBench Hard - Spatial navigation reasoning",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "spatial"
    ],
    "function_name": "bbh_navigate",
    "is_alpha": false
  },
  {
    "name": "BBH: Reasoning About Colored Objects",
    "description": "BigBench Hard - Reasoning about colored objects",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought"
    ],
    "function_name": "bbh_reasoning_about_colored_objects",
    "is_alpha": false
  },
  {
    "name": "BBH: Ruin Names",
    "description": "BigBench Hard - Word manipulation and reasoning",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "wordplay"
    ],
    "function_name": "bbh_ruin_names",
    "is_alpha": false
  },
  {
    "name": "BBH: Salient Translation Error Detection",
    "description": "BigBench Hard - Detecting translation errors",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "translation"
    ],
    "function_name": "bbh_salient_translation_error_detection",
    "is_alpha": false
  },
  {
    "name": "BBH: Snarks",
    "description": "BigBench Hard - Understanding sarcasm and irony",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "sarcasm"
    ],
    "function_name": "bbh_snarks",
    "is_alpha": false
  },
  {
    "name": "GLUE (All Tasks)",
    "description": "General Language Understanding Evaluation benchmark suite",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli",
      "sentiment",
      "similarity"
    ],
    "function_name": "glue",
    "is_alpha": false
  },
  {
    "name": "GLUE: CoLA",
    "description": "Corpus of Linguistic Acceptability",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_cola",
    "is_alpha": false
  },
  {
    "name": "GLUE: MNLI",
    "description": "Multi-Genre Natural Language Inference",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_mnli",
    "is_alpha": false
  },
  {
    "name": "GLUE: MNLI-MM",
    "description": "MNLI Mismatched",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_mnli_mismatched",
    "is_alpha": false
  },
  {
    "name": "GLUE: MRPC",
    "description": "Microsoft Research Paraphrase Corpus",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_mrpc",
    "is_alpha": false
  },
  {
    "name": "GLUE: QNLI",
    "description": "Question Natural Language Inference",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_qnli",
    "is_alpha": false
  },
  {
    "name": "GLUE: QQP",
    "description": "Quora Question Pairs",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_qqp",
    "is_alpha": false
  },
  {
    "name": "GLUE: RTE",
    "description": "Recognizing Textual Entailment",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_rte",
    "is_alpha": false
  },
  {
    "name": "GLUE: SST-2",
    "description": "Stanford Sentiment Treebank",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_sst2",
    "is_alpha": false
  },
  {
    "name": "GLUE: STS-B",
    "description": "Semantic Textual Similarity Benchmark",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_stsb",
    "is_alpha": false
  },
  {
    "name": "GLUE: WNLI",
    "description": "Winograd Natural Language Inference",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "glue",
      "nli"
    ],
    "function_name": "glue_wnli",
    "is_alpha": false
  },
  {
    "name": "GMCQ",
    "description": "GitHub Multiple Choice Questions",
    "name": "BBH: Sports Understanding",
    "description": "BigBench Hard - Sports knowledge and reasoning",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "sports"
    ],
    "function_name": "bbh_sports_understanding",
    "is_alpha": false
  },
  {
    "name": "BBH: Temporal Sequences",
    "description": "BigBench Hard - Understanding temporal sequences",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "temporal"
    ],
    "function_name": "bbh_temporal_sequences",
    "is_alpha": false
  },
  {
    "name": "BBH: Tracking Shuffled Objects (3 Objects)",
    "description": "BigBench Hard - Tracking three shuffled objects",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "tracking"
    ],
    "function_name": "bbh_tracking_shuffled_objects_three_objects",
    "is_alpha": false
  },
  {
    "name": "BBH: Tracking Shuffled Objects (5 Objects)",
    "description": "BigBench Hard - Tracking five shuffled objects",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "tracking"
    ],
    "function_name": "bbh_tracking_shuffled_objects_five_objects",
    "is_alpha": false
  },
  {
    "name": "BBH: Tracking Shuffled Objects (7 Objects)",
    "description": "BigBench Hard - Tracking seven shuffled objects",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench",
      "chain-of-thought",
      "tracking"
    ],
    "function_name": "bbh_tracking_shuffled_objects_seven_objects",
    "is_alpha": false
  },
  {
    "name": "BRUMO 2025",
    "description": "Bruno Mathematical Olympiad 2025",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "olympiad",
      "2025"
    ],
    "function_name": "brumo_2025",
    "is_alpha": false
  },
  {
    "name": "BigBench: Anachronisms",
    "description": "BigBench MCQ task: anachronisms",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_anachronisms",
    "is_alpha": false
  },
  {
    "name": "BigBench: Analogical Similarity",
    "description": "BigBench MCQ task: analogical_similarity",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_analogical_similarity",
    "is_alpha": false
  },
  {
    "name": "BigBench: Analytic Entailment",
    "description": "BigBench MCQ task: analytic_entailment",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_analytic_entailment",
    "is_alpha": false
  },
  {
    "name": "BigBench: Arithmetic",
    "description": "BigBench MCQ task: arithmetic",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_arithmetic",
    "is_alpha": false
  },
  {
    "name": "BigBench: Authorship Verification",
    "description": "BigBench MCQ task: authorship_verification",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_authorship_verification",
    "is_alpha": false
  },
  {
    "name": "BigBench: Bbq Lite Json",
    "description": "BigBench MCQ task: bbq_lite_json",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_bbq_lite_json",
    "is_alpha": false
  },
  {
    "name": "BigBench: Causal Judgment",
    "description": "BigBench MCQ task: causal_judgment",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_causal_judgment",
    "is_alpha": false
  },
  {
    "name": "BigBench: Cause And Effect",
    "description": "BigBench MCQ task: cause_and_effect",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_cause_and_effect",
    "is_alpha": false
  },
  {
    "name": "BigBench: Checkmate In One",
    "description": "BigBench MCQ task: checkmate_in_one",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_checkmate_in_one",
    "is_alpha": false
  },
  {
    "name": "BigBench: Cifar10 Classification",
    "description": "BigBench MCQ task: cifar10_classification",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_cifar10_classification",
    "is_alpha": false
  },
  {
    "name": "BigBench: Code Line Description",
    "description": "BigBench MCQ task: code_line_description",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_code_line_description",
    "is_alpha": false
  },
  {
    "name": "BigBench: Color",
    "description": "BigBench MCQ task: color",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_color",
    "is_alpha": false
  },
  {
    "name": "BigBench: Common Morpheme",
    "description": "BigBench MCQ task: common_morpheme",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_common_morpheme",
    "is_alpha": false
  },
  {
    "name": "BigBench: Conceptual Combinations",
    "description": "BigBench MCQ task: conceptual_combinations",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_conceptual_combinations",
    "is_alpha": false
  },
  {
    "name": "BigBench: Contextual Parametric Knowledge Conflicts",
    "description": "BigBench MCQ task: contextual_parametric_knowledge_conflicts",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_contextual_parametric_knowledge_conflicts",
    "is_alpha": false
  },
  {
    "name": "BigBench: Crash Blossom",
    "description": "BigBench MCQ task: crash_blossom",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_crash_blossom",
    "is_alpha": false
  },
  {
    "name": "BigBench: Crass Ai",
    "description": "BigBench MCQ task: crass_ai",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_crass_ai",
    "is_alpha": false
  },
  {
    "name": "BigBench: Cryobiology Spanish",
    "description": "BigBench MCQ task: cryobiology_spanish",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_cryobiology_spanish",
    "is_alpha": false
  },
  {
    "name": "BigBench: Cs Algorithms",
    "description": "BigBench MCQ task: cs_algorithms",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_cs_algorithms",
    "is_alpha": false
  },
  {
    "name": "BigBench: Dark Humor Detection",
    "description": "BigBench MCQ task: dark_humor_detection",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_dark_humor_detection",
    "is_alpha": false
  },
  {
    "name": "BigBench: Date Understanding",
    "description": "BigBench MCQ task: date_understanding",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_date_understanding",
    "is_alpha": false
  },
  {
    "name": "BigBench: Disambiguation Qa",
    "description": "BigBench MCQ task: disambiguation_qa",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_disambiguation_qa",
    "is_alpha": false
  },
  {
    "name": "BigBench: Discourse Marker Prediction",
    "description": "BigBench MCQ task: discourse_marker_prediction",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_discourse_marker_prediction",
    "is_alpha": false
  },
  {
    "name": "BigBench: Dyck Languages",
    "description": "BigBench MCQ task: dyck_languages",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_dyck_languages",
    "is_alpha": false
  },
  {
    "name": "BigBench: Elementary Math Qa",
    "description": "BigBench MCQ task: elementary_math_qa",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_elementary_math_qa",
    "is_alpha": false
  },
  {
    "name": "BigBench: Emoji Movie",
    "description": "BigBench MCQ task: emoji_movie",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_emoji_movie",
    "is_alpha": false
  },
  {
    "name": "BigBench: Emojis Emotion Prediction",
    "description": "BigBench MCQ task: emojis_emotion_prediction",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_emojis_emotion_prediction",
    "is_alpha": false
  },
  {
    "name": "BigBench: Empirical Judgments",
    "description": "BigBench MCQ task: empirical_judgments",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_empirical_judgments",
    "is_alpha": false
  },
  {
    "name": "BigBench: English Proverbs",
    "description": "BigBench MCQ task: english_proverbs",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_english_proverbs",
    "is_alpha": false
  },
  {
    "name": "BigBench: English Russian Proverbs",
    "description": "BigBench MCQ task: english_russian_proverbs",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_english_russian_proverbs",
    "is_alpha": false
  },
  {
    "name": "BigBench: Entailed Polarity",
    "description": "BigBench MCQ task: entailed_polarity",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_entailed_polarity",
    "is_alpha": false
  },
  {
    "name": "BigBench: Entailed Polarity Hindi",
    "description": "BigBench MCQ task: entailed_polarity_hindi",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_entailed_polarity_hindi",
    "is_alpha": false
  },
  {
    "name": "BigBench: Epistemic Reasoning",
    "description": "BigBench MCQ task: epistemic_reasoning",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_epistemic_reasoning",
    "is_alpha": false
  },
  {
    "name": "BigBench: Evaluating Information Essentiality",
    "description": "BigBench MCQ task: evaluating_information_essentiality",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_evaluating_information_essentiality",
    "is_alpha": false
  },
  {
    "name": "BigBench: Fact Checker",
    "description": "BigBench MCQ task: fact_checker",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_fact_checker",
    "is_alpha": false
  },
  {
    "name": "BigBench: Fantasy Reasoning",
    "description": "BigBench MCQ task: fantasy_reasoning",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_fantasy_reasoning",
    "is_alpha": false
  },
  {
    "name": "BigBench: Figure Of Speech Detection",
    "description": "BigBench MCQ task: figure_of_speech_detection",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_figure_of_speech_detection",
    "is_alpha": false
  },
  {
    "name": "BigBench: Formal Fallacies Syllogisms Negation",
    "description": "BigBench MCQ task: formal_fallacies_syllogisms_negation",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_formal_fallacies_syllogisms_negation",
    "is_alpha": false
  },
  {
    "name": "BigBench: General Knowledge",
    "description": "BigBench MCQ task: general_knowledge",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_general_knowledge",
    "is_alpha": false
  },
  {
    "name": "BigBench: Geometric Shapes",
    "description": "BigBench MCQ task: geometric_shapes",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_geometric_shapes",
    "is_alpha": false
  },
  {
    "name": "BigBench: Goal Step Wikihow",
    "description": "BigBench MCQ task: goal_step_wikihow",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_goal_step_wikihow",
    "is_alpha": false
  },
  {
    "name": "BigBench: Gre Reading Comprehension",
    "description": "BigBench MCQ task: gre_reading_comprehension",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_gre_reading_comprehension",
    "is_alpha": false
  },
  {
    "name": "BigBench: Hhh Alignment",
    "description": "BigBench MCQ task: hhh_alignment",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_hhh_alignment",
    "is_alpha": false
  },
  {
    "name": "BigBench: Hindu Knowledge",
    "description": "BigBench MCQ task: hindu_knowledge",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_hindu_knowledge",
    "is_alpha": false
  },
  {
    "name": "BigBench: Hinglish Toxicity",
    "description": "BigBench MCQ task: hinglish_toxicity",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_hinglish_toxicity",
    "is_alpha": false
  },
  {
    "name": "BigBench: Human Organs Senses",
    "description": "BigBench MCQ task: human_organs_senses",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_human_organs_senses",
    "is_alpha": false
  },
  {
    "name": "BigBench: Hyperbaton",
    "description": "BigBench MCQ task: hyperbaton",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_hyperbaton",
    "is_alpha": false
  },
  {
    "name": "BigBench: Identify Math Theorems",
    "description": "BigBench MCQ task: identify_math_theorems",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_identify_math_theorems",
    "is_alpha": false
  },
  {
    "name": "BigBench: Identify Odd Metaphor",
    "description": "BigBench MCQ task: identify_odd_metaphor",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_identify_odd_metaphor",
    "is_alpha": false
  },
  {
    "name": "BigBench: Implicatures",
    "description": "BigBench MCQ task: implicatures",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_implicatures",
    "is_alpha": false
  },
  {
    "name": "BigBench: Implicit Relations",
    "description": "BigBench MCQ task: implicit_relations",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_implicit_relations",
    "is_alpha": false
  },
  {
    "name": "BigBench: Indic Cause And Effect",
    "description": "BigBench MCQ task: indic_cause_and_effect",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_indic_cause_and_effect",
    "is_alpha": false
  },
  {
    "name": "BigBench: Intent Recognition",
    "description": "BigBench MCQ task: intent_recognition",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_intent_recognition",
    "is_alpha": false
  },
  {
    "name": "BigBench: International Phonetic Alphabet Nli",
    "description": "BigBench MCQ task: international_phonetic_alphabet_nli",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_international_phonetic_alphabet_nli",
    "is_alpha": false
  },
  {
    "name": "BigBench: Intersect Geometry",
    "description": "BigBench MCQ task: intersect_geometry",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_intersect_geometry",
    "is_alpha": false
  },
  {
    "name": "BigBench: Irony Identification",
    "description": "BigBench MCQ task: irony_identification",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_irony_identification",
    "is_alpha": false
  },
  {
    "name": "BigBench: Kanji Ascii",
    "description": "BigBench MCQ task: kanji_ascii",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_kanji_ascii",
    "is_alpha": false
  },
  {
    "name": "BigBench: Kannada",
    "description": "BigBench MCQ task: kannada",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_kannada",
    "is_alpha": false
  },
  {
    "name": "BigBench: Key Value Maps",
    "description": "BigBench MCQ task: key_value_maps",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_key_value_maps",
    "is_alpha": false
  },
  {
    "name": "BigBench: Known Unknowns",
    "description": "BigBench MCQ task: known_unknowns",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_known_unknowns",
    "is_alpha": false
  },
  {
    "name": "BigBench: Language Identification",
    "description": "BigBench MCQ task: language_identification",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_language_identification",
    "is_alpha": false
  },
  {
    "name": "BigBench: Logic Grid Puzzle",
    "description": "BigBench MCQ task: logic_grid_puzzle",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_logic_grid_puzzle",
    "is_alpha": false
  },
  {
    "name": "BigBench: Logical Args",
    "description": "BigBench MCQ task: logical_args",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_logical_args",
    "is_alpha": false
  },
  {
    "name": "BigBench: Logical Deduction",
    "description": "BigBench MCQ task: logical_deduction",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_logical_deduction",
    "is_alpha": false
  },
  {
    "name": "BigBench: Logical Fallacy Detection",
    "description": "BigBench MCQ task: logical_fallacy_detection",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_logical_fallacy_detection",
    "is_alpha": false
  },
  {
    "name": "BigBench: Logical Sequence",
    "description": "BigBench MCQ task: logical_sequence",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_logical_sequence",
    "is_alpha": false
  },
  {
    "name": "BigBench: Mathematical Induction",
    "description": "BigBench MCQ task: mathematical_induction",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_mathematical_induction",
    "is_alpha": false
  },
  {
    "name": "BigBench: Medical Questions Russian",
    "description": "BigBench MCQ task: medical_questions_russian",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_medical_questions_russian",
    "is_alpha": false
  },
  {
    "name": "BigBench: Metaphor Boolean",
    "description": "BigBench MCQ task: metaphor_boolean",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_metaphor_boolean",
    "is_alpha": false
  },
  {
    "name": "BigBench: Metaphor Understanding",
    "description": "BigBench MCQ task: metaphor_understanding",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_metaphor_understanding",
    "is_alpha": false
  },
  {
    "name": "BigBench: Minute Mysteries Qa",
    "description": "BigBench MCQ task: minute_mysteries_qa",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_minute_mysteries_qa",
    "is_alpha": false
  },
  {
    "name": "BigBench: Misconceptions",
    "description": "BigBench MCQ task: misconceptions",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_misconceptions",
    "is_alpha": false
  },
  {
    "name": "BigBench: Misconceptions Russian",
    "description": "BigBench MCQ task: misconceptions_russian",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_misconceptions_russian",
    "is_alpha": false
  },
  {
    "name": "BigBench: Mnist Ascii",
    "description": "BigBench MCQ task: mnist_ascii",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_mnist_ascii",
    "is_alpha": false
  },
  {
    "name": "BigBench: Moral Permissibility",
    "description": "BigBench MCQ task: moral_permissibility",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_moral_permissibility",
    "is_alpha": false
  },
  {
    "name": "BigBench: Movie Dialog Same Or Different",
    "description": "BigBench MCQ task: movie_dialog_same_or_different",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_movie_dialog_same_or_different",
    "is_alpha": false
  },
  {
    "name": "BigBench: Movie Recommendation",
    "description": "BigBench MCQ task: movie_recommendation",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_movie_recommendation",
    "is_alpha": false
  },
  {
    "name": "BigBench: Navigate",
    "description": "BigBench MCQ task: navigate",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_navigate",
    "is_alpha": false
  },
  {
    "name": "BigBench: Nonsense Words Grammar",
    "description": "BigBench MCQ task: nonsense_words_grammar",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_nonsense_words_grammar",
    "is_alpha": false
  },
  {
    "name": "BigBench: Novel Concepts",
    "description": "BigBench MCQ task: novel_concepts",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_novel_concepts",
    "is_alpha": false
  },
  {
    "name": "BigBench: Odd One Out",
    "description": "BigBench MCQ task: odd_one_out",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_odd_one_out",
    "is_alpha": false
  },
  {
    "name": "BigBench: Parsinlu Qa",
    "description": "BigBench MCQ task: parsinlu_qa",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_parsinlu_qa",
    "is_alpha": false
  },
  {
    "name": "BigBench: Penguins In A Table",
    "description": "BigBench MCQ task: penguins_in_a_table",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_penguins_in_a_table",
    "is_alpha": false
  },
  {
    "name": "BigBench: Periodic Elements",
    "description": "BigBench MCQ task: periodic_elements",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_periodic_elements",
    "is_alpha": false
  },
  {
    "name": "BigBench: Persian Idioms",
    "description": "BigBench MCQ task: persian_idioms",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_persian_idioms",
    "is_alpha": false
  },
  {
    "name": "BigBench: Phrase Relatedness",
    "description": "BigBench MCQ task: phrase_relatedness",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_phrase_relatedness",
    "is_alpha": false
  },
  {
    "name": "BigBench: Physical Intuition",
    "description": "BigBench MCQ task: physical_intuition",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_physical_intuition",
    "is_alpha": false
  },
  {
    "name": "BigBench: Physics",
    "description": "BigBench MCQ task: physics",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_physics",
    "is_alpha": false
  },
  {
    "name": "BigBench: Play Dialog Same Or Different",
    "description": "BigBench MCQ task: play_dialog_same_or_different",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_play_dialog_same_or_different",
    "is_alpha": false
  },
  {
    "name": "BigBench: Presuppositions As Nli",
    "description": "BigBench MCQ task: presuppositions_as_nli",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_presuppositions_as_nli",
    "is_alpha": false
  },
  {
    "name": "BigBench: Question Selection",
    "description": "BigBench MCQ task: question_selection",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_question_selection",
    "is_alpha": false
  },
  {
    "name": "BigBench: Real Or Fake Text",
    "description": "BigBench MCQ task: real_or_fake_text",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_real_or_fake_text",
    "is_alpha": false
  },
  {
    "name": "BigBench: Reasoning About Colored Objects",
    "description": "BigBench MCQ task: reasoning_about_colored_objects",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_reasoning_about_colored_objects",
    "is_alpha": false
  },
  {
    "name": "BigBench: Rhyming",
    "description": "BigBench MCQ task: rhyming",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_rhyming",
    "is_alpha": false
  },
  {
    "name": "BigBench: Riddle Sense",
    "description": "BigBench MCQ task: riddle_sense",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_riddle_sense",
    "is_alpha": false
  },
  {
    "name": "BigBench: Ruin Names",
    "description": "BigBench MCQ task: ruin_names",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_ruin_names",
    "is_alpha": false
  },
  {
    "name": "BigBench: Salient Translation Error Detection",
    "description": "BigBench MCQ task: salient_translation_error_detection",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_salient_translation_error_detection",
    "is_alpha": false
  },
  {
    "name": "BigBench: Sentence Ambiguity",
    "description": "BigBench MCQ task: sentence_ambiguity",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_sentence_ambiguity",
    "is_alpha": false
  },
  {
    "name": "BigBench: Similarities Abstraction",
    "description": "BigBench MCQ task: similarities_abstraction",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_similarities_abstraction",
    "is_alpha": false
  },
  {
    "name": "BigBench: Simple Ethical Questions",
    "description": "BigBench MCQ task: simple_ethical_questions",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_simple_ethical_questions",
    "is_alpha": false
  },
  {
    "name": "BigBench: Snarks",
    "description": "BigBench MCQ task: snarks",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_snarks",
    "is_alpha": false
  },
  {
    "name": "BigBench: Social Iqa",
    "description": "BigBench MCQ task: social_iqa",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_social_iqa",
    "is_alpha": false
  },
  {
    "name": "BigBench: Social Support",
    "description": "BigBench MCQ task: social_support",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_social_support",
    "is_alpha": false
  },
  {
    "name": "BigBench: Sports Understanding",
    "description": "BigBench MCQ task: sports_understanding",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_sports_understanding",
    "is_alpha": false
  },
  {
    "name": "BigBench: Strange Stories",
    "description": "BigBench MCQ task: strange_stories",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_strange_stories",
    "is_alpha": false
  },
  {
    "name": "BigBench: Strategyqa",
    "description": "BigBench MCQ task: strategyqa",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_strategyqa",
    "is_alpha": false
  },
  {
    "name": "BigBench: Suicide Risk",
    "description": "BigBench MCQ task: suicide_risk",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_suicide_risk",
    "is_alpha": false
  },
  {
    "name": "BigBench: Swahili English Proverbs",
    "description": "BigBench MCQ task: swahili_english_proverbs",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_swahili_english_proverbs",
    "is_alpha": false
  },
  {
    "name": "BigBench: Swedish To German Proverbs",
    "description": "BigBench MCQ task: swedish_to_german_proverbs",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_swedish_to_german_proverbs",
    "is_alpha": false
  },
  {
    "name": "BigBench: Symbol Interpretation",
    "description": "BigBench MCQ task: symbol_interpretation",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_symbol_interpretation",
    "is_alpha": false
  },
  {
    "name": "BigBench: Temporal Sequences",
    "description": "BigBench MCQ task: temporal_sequences",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_temporal_sequences",
    "is_alpha": false
  },
  {
    "name": "BigBench: Timedial",
    "description": "BigBench MCQ task: timedial",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_timedial",
    "is_alpha": false
  },
  {
    "name": "BigBench: Tracking Shuffled Objects",
    "description": "BigBench MCQ task: tracking_shuffled_objects",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_tracking_shuffled_objects",
    "is_alpha": false
  },
  {
    "name": "BigBench: Understanding Fables",
    "description": "BigBench MCQ task: understanding_fables",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_understanding_fables",
    "is_alpha": false
  },
  {
    "name": "BigBench: Undo Permutation",
    "description": "BigBench MCQ task: undo_permutation",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_undo_permutation",
    "is_alpha": false
  },
  {
    "name": "BigBench: Unit Conversion",
    "description": "BigBench MCQ task: unit_conversion",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_unit_conversion",
    "is_alpha": false
  },
  {
    "name": "BigBench: Unit Interpretation",
    "description": "BigBench MCQ task: unit_interpretation",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_unit_interpretation",
    "is_alpha": false
  },
  {
    "name": "BigBench: Vitaminc Fact Verification",
    "description": "BigBench MCQ task: vitaminc_fact_verification",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_vitaminc_fact_verification",
    "is_alpha": false
  },
  {
    "name": "BigBench: What Is The Tao",
    "description": "BigBench MCQ task: what_is_the_tao",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_what_is_the_tao",
    "is_alpha": false
  },
  {
    "name": "BigBench: Which Wiki Edit",
    "description": "BigBench MCQ task: which_wiki_edit",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_which_wiki_edit",
    "is_alpha": false
  },
  {
    "name": "BigBench: Winowhy",
    "description": "BigBench MCQ task: winowhy",
    "category": "bigbench",
    "tags": [
      "multiple-choice",
      "reasoning",
      "bigbench"
    ],
    "function_name": "bigbench_winowhy",
    "is_alpha": false
  },
  {
    "name": "BoolQ",
    "description": "BoolQ: A Question Answering Dataset for Boolean Reasoning",
    "category": "core",
    "tags": [
      "boolean-reasoning",
      "question-answering"
    ],
    "function_name": "boolq",
    "is_alpha": false
  },
  {
    "name": "BrowseComp",
    "description": "A Simple Yet Challenging Benchmark for Browsing Agents - evaluates model performance on browsing-related tasks",
    "category": "core",
    "tags": [
      "browsing",
      "web",
      "reasoning",
      "graded"
    ],
    "function_name": "browsecomp",
    "is_alpha": false
  },
  {
    "name": "CTI-Bench ATE",
    "description": "Extracting MITRE ATT&CK techniques from malware and threat descriptions",
    "category": "cybersecurity",
    "tags": [
      "extraction",
      "cybersecurity"
    ],
    "function_name": "cti_bench_ate",
    "is_alpha": false
  },
  {
    "name": "CTI-Bench MCQ",
    "description": "Multiple-choice questions evaluating understanding of CTI standards, threats, detection strategies, and best practices using authoritative sources like NIST and MITRE",
    "category": "cybersecurity",
    "tags": [
      "multiple-choice",
      "cybersecurity",
      "knowledge"
    ],
    "function_name": "cti_bench_mcq",
    "is_alpha": false
  },
  {
    "name": "CTI-Bench RCM",
    "description": "Mapping CVE descriptions to CWE categories to evaluate vulnerability classification ability",
    "category": "cybersecurity",
    "tags": [
      "classification",
      "cybersecurity"
    ],
    "function_name": "cti_bench_rcm",
    "is_alpha": false
  },
  {
    "name": "CTI-Bench VSP",
    "description": "Calculating CVSS scores from vulnerability descriptions to assess severity evaluation skills",
    "category": "cybersecurity",
    "tags": [
      "regression",
      "cybersecurity"
    ],
    "function_name": "cti_bench_vsp",
    "is_alpha": false
  },
  {
    "name": "ClockBench",
    "description": "Clock benchmark - time-based reasoning tasks",
    "category": "community",
    "tags": [
      "time",
      "analog",
      "clock",
      "reasoning"
    ],
    "function_name": "clockbench",
    "is_alpha": false
  },
  {
    "name": "DROP",
    "description": "Reading comprehension benchmark requiring discrete reasoning over paragraphs (arithmetic, counting, sorting)",
    "category": "core",
    "tags": [
      "reading-comprehension",
      "reasoning",
      "arithmetic",
      "counting",
      "sorting"
    ],
    "function_name": "drop",
    "is_alpha": false
  },
  {
    "name": "DetailBench",
    "description": "Tests whether LLMs notify users about wrong facts in a text while they are tasked to translate said text",
    "category": "community",
    "tags": [
      "knowledge",
      "graded",
      "instruction-following"
    ],
    "function_name": "detailbench",
    "is_alpha": false
  },
  {
    "name": "Exercism",
    "description": "Multi-language coding benchmark with real-world programming exercises across Python, Go, JavaScript, Java, and Rust",
    "category": "core",
    "tags": [
      "coding",
      "multi-language",
      "execution",
      "docker"
    ],
    "function_name": "exercism",
    "is_alpha": false
  },
  {
    "name": "Exercism (Go)",
    "description": "Go coding tasks from the Exercism benchmark",
    "category": "core",
    "tags": [
      "coding",
      "go",
      "execution",
      "docker"
    ],
    "function_name": "exercism_go",
    "is_alpha": false
  },
  {
    "name": "Exercism (Java)",
    "description": "Java coding tasks from the Exercism benchmark",
    "category": "core",
    "tags": [
      "coding",
      "java",
      "execution",
      "docker"
    ],
    "function_name": "exercism_java",
    "is_alpha": false
  },
  {
    "name": "Exercism (JavaScript)",
    "description": "JavaScript coding tasks from the Exercism benchmark",
    "category": "core",
    "tags": [
      "coding",
      "javascript",
      "execution",
      "docker"
    ],
    "function_name": "exercism_javascript",
    "is_alpha": false
  },
  {
    "name": "Exercism (Python)",
    "description": "Python coding tasks from the Exercism benchmark",
    "category": "core",
    "tags": [
      "coding",
      "python",
      "execution",
      "docker"
    ],
    "function_name": "exercism_python",
    "is_alpha": false
  },
  {
    "name": "Exercism (Rust)",
    "description": "Rust coding tasks from the Exercism benchmark",
    "category": "core",
    "tags": [
      "coding",
      "rust",
      "execution",
      "docker"
    ],
    "function_name": "exercism_rust",
    "is_alpha": false
  },
  {
    "name": "GMCQ",
    "description": "GitHub Multiple Choice Questions",
    "category": "core",
    "tags": [
      "code-understanding"
    ],
    "function_name": "rootly_gmcq",
    "is_alpha": false
  },
  {
    "name": "GPQA Diamond",
    "description": "Graduate-level Google-Proof Q&A in biology, chemistry, and physics",
    "category": "core",
    "tags": [
      "multiple-choice",
      "science",
      "graduate-level"
    ],
    "function_name": "gpqa_diamond",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU (42 Languages)",
    "description": "Culturally adapted multilingual MMLU with 42 languages",
    "category": "core",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-sensitivity",
      "mmlu"
    ],
    "function_name": "global_mmlu",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Amharic",
    "description": "Global-MMLU culturally adapted MMLU for Amharic (am)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_amharic",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Arabic",
    "description": "Global-MMLU culturally adapted MMLU for Arabic (ar)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_arabic",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Bengali",
    "description": "Global-MMLU culturally adapted MMLU for Bengali (bn)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_bengali",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Chichewa",
    "description": "Global-MMLU culturally adapted MMLU for Chichewa (ny)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_chichewa",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Chinese",
    "description": "Global-MMLU culturally adapted MMLU for Chinese (zh)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_chinese",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Czech",
    "description": "Global-MMLU culturally adapted MMLU for Czech (cs)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_czech",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Dutch",
    "description": "Global-MMLU culturally adapted MMLU for Dutch (nl)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_dutch",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: English",
    "description": "Global-MMLU culturally adapted MMLU for English (en)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_english",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Filipino",
    "description": "Global-MMLU culturally adapted MMLU for Filipino (fil)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_filipino",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: French",
    "description": "Global-MMLU culturally adapted MMLU for French (fr)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_french",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: German",
    "description": "Global-MMLU culturally adapted MMLU for German (de)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_german",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Greek",
    "description": "Global-MMLU culturally adapted MMLU for Greek (el)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_greek",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Hausa",
    "description": "Global-MMLU culturally adapted MMLU for Hausa (ha)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_hausa",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Hebrew",
    "description": "Global-MMLU culturally adapted MMLU for Hebrew (he)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_hebrew",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Hindi",
    "description": "Global-MMLU culturally adapted MMLU for Hindi (hi)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_hindi",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Igbo",
    "description": "Global-MMLU culturally adapted MMLU for Igbo (ig)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_igbo",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Indonesian",
    "description": "Global-MMLU culturally adapted MMLU for Indonesian (id)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_indonesian",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Italian",
    "description": "Global-MMLU culturally adapted MMLU for Italian (it)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_italian",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Japanese",
    "description": "Global-MMLU culturally adapted MMLU for Japanese (ja)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_japanese",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Korean",
    "description": "Global-MMLU culturally adapted MMLU for Korean (ko)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_korean",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Kyrgyz",
    "description": "Global-MMLU culturally adapted MMLU for Kyrgyz (ky)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_kyrgyz",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Lithuanian",
    "description": "Global-MMLU culturally adapted MMLU for Lithuanian (lt)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_lithuanian",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Malagasy",
    "description": "Global-MMLU culturally adapted MMLU for Malagasy (mg)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_malagasy",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Malay",
    "description": "Global-MMLU culturally adapted MMLU for Malay (ms)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_malay",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Nepali",
    "description": "Global-MMLU culturally adapted MMLU for Nepali (ne)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_nepali",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Persian",
    "description": "Global-MMLU culturally adapted MMLU for Persian (fa)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_persian",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Polish",
    "description": "Global-MMLU culturally adapted MMLU for Polish (pl)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_polish",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Portuguese",
    "description": "Global-MMLU culturally adapted MMLU for Portuguese (pt)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_portuguese",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Romanian",
    "description": "Global-MMLU culturally adapted MMLU for Romanian (ro)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_romanian",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Russian",
    "description": "Global-MMLU culturally adapted MMLU for Russian (ru)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_russian",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Serbian",
    "description": "Global-MMLU culturally adapted MMLU for Serbian (sr)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_serbian",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Shona",
    "description": "Global-MMLU culturally adapted MMLU for Shona (sn)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_shona",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Sinhala",
    "description": "Global-MMLU culturally adapted MMLU for Sinhala (si)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_sinhala",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Somali",
    "description": "Global-MMLU culturally adapted MMLU for Somali (so)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_somali",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Spanish",
    "description": "Global-MMLU culturally adapted MMLU for Spanish (es)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_spanish",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Swahili",
    "description": "Global-MMLU culturally adapted MMLU for Swahili (sw)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_swahili",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Swedish",
    "description": "Global-MMLU culturally adapted MMLU for Swedish (sv)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_swedish",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Telugu",
    "description": "Global-MMLU culturally adapted MMLU for Telugu (te)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_telugu",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Turkish",
    "description": "Global-MMLU culturally adapted MMLU for Turkish (tr)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_turkish",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Ukrainian",
    "description": "Global-MMLU culturally adapted MMLU for Ukrainian (uk)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_ukrainian",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Vietnamese",
    "description": "Global-MMLU culturally adapted MMLU for Vietnamese (vi)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_vietnamese",
    "is_alpha": false
  },
  {
    "name": "Global-MMLU: Yoruba",
    "description": "Global-MMLU culturally adapted MMLU for Yoruba (yo)",
    "category": "global-mmlu",
    "tags": [
      "multiple-choice",
      "multilingual",
      "cultural-adaptation",
      "global-mmlu"
    ],
    "function_name": "global_mmlu_yoruba",
    "is_alpha": false
  },
  {
    "name": "GraphWalks",
    "description": "Multi-hop reasoning on graphs - both BFS and parent finding tasks",
    "category": "core",
    "tags": [
      "long-context",
      "graphs",
      "reasoning",
      "alpha"
    ],
    "function_name": "graphwalks",
    "is_alpha": true
  },
  {
    "name": "GraphWalks BFS",
    "description": "Multi-hop reasoning on graphs - BFS traversal tasks only",
    "category": "core",
    "tags": [
      "long-context",
      "graphs",
      "reasoning",
      "bfs",
      "alpha"
    ],
    "function_name": "graphwalks_bfs",
    "is_alpha": true
  },
  {
    "name": "GraphWalks Parents",
    "description": "Multi-hop reasoning on graphs - parent finding tasks only",
    "category": "core",
    "tags": [
      "long-context",
      "graphs",
      "reasoning",
      "parents",
      "alpha"
    ],
    "function_name": "graphwalks_parents",
    "is_alpha": true
  },
  {
    "name": "HMMT Feb 2023",
    "description": "Harvard-MIT Mathematics Tournament February 2023",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "hmmt",
      "2023"
    ],
    "function_name": "hmmt_feb_2023",
    "is_alpha": false
  },
  {
    "name": "HMMT Feb 2024",
    "description": "Harvard-MIT Mathematics Tournament February 2024",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "hmmt",
      "2024"
    ],
    "function_name": "hmmt_feb_2024",
    "is_alpha": false
  },
  {
    "name": "HMMT Feb 2025",
    "description": "Harvard-MIT Mathematics Tournament February 2025",
    "category": "math",
    "tags": [
      "math",
      "competition",
      "hmmt",
      "2025"
    ],
    "function_name": "hmmt_feb_2025",
    "is_alpha": false
  },
  {
    "name": "HeadQA",
    "description": "Spanish healthcare specialization exam questions (Spanish and English)",
    "category": "core",
    "tags": [
      "multiple-choice",
      "medical",
      "healthcare",
      "multilingual"
    ],
    "function_name": "headqa",
    "is_alpha": false
  },
  {
    "name": "HeadQA (English)",
    "description": "Spanish healthcare specialization exam questions in English",
    "category": "core",
    "tags": [
      "multiple-choice",
      "medical",
      "healthcare",
      "english"
    ],
    "function_name": "headqa_en",
    "is_alpha": false
  },
  {
    "name": "HeadQA (Spanish)",
    "description": "Spanish healthcare specialization exam questions in Spanish",
    "category": "core",
    "tags": [
      "multiple-choice",
      "medical",
      "healthcare",
      "spanish"
    ],
    "function_name": "headqa_es",
    "is_alpha": false
  },
  {
    "name": "HealthBench",
    "description": "Medical dialogue evaluation using physician-created rubrics for assessing healthcare conversations",
    "category": "core",
    "tags": [
      "medical",
      "dialogue",
      "graded",
      "rubric-based"
    ],
    "function_name": "healthbench",
    "is_alpha": false
  },
  {
    "name": "HealthBench Consensus",
    "description": "Medical dialogue cases with strong physician consensus on appropriate responses",
    "category": "core",
    "tags": [
      "medical",
      "dialogue",
      "graded",
      "rubric-based",
      "consensus"
    ],
    "function_name": "healthbench_consensus",
    "is_alpha": false
  },
  {
    "name": "HealthBench Hard",
    "description": "Most challenging medical dialogue cases from HealthBench requiring nuanced medical knowledge",
    "category": "core",
    "tags": [
      "medical",
      "dialogue",
      "graded",
      "rubric-based",
      "hard"
    ],
    "function_name": "healthbench_hard",
    "is_alpha": false
  },
  {
    "name": "HellaSwag",
    "description": "Adversarially-filtered sentence completion benchmark for commonsense reasoning",
    "category": "core",
    "tags": [
      "multiple-choice",
      "commonsense-reasoning",
      "sentence-completion"
    ],
    "function_name": "hellaswag",
    "is_alpha": false
  },
  {
    "name": "HumanEval",
    "description": "Code generation benchmark with 164 programming problems",
    "category": "core",
    "tags": [
      "coding",
      "generation",
      "execution"
    ],
    "function_name": "humaneval",
    "is_alpha": false
  },
  {
    "name": "Humanity's Last Exam",
    "description": "Multi-modal benchmark at the frontier of human knowledge - 2,500 questions across mathematics, humanities, and natural sciences designed by subject-matter experts globally",
    "category": "core",
    "tags": [
      "knowledge",
      "reasoning",
      "multi-modal",
      "graded",
      "frontier"
    ],
    "function_name": "hle",
    "is_alpha": false
  },
  {
    "name": "Humanity's Last Exam (Text-Only)",
    "description": "Text-only variant of HLE with multi-modal questions filtered out - evaluates models without vision capabilities on text-based questions from the frontier of human knowledge",
    "category": "core",
    "tags": [
      "knowledge",
      "reasoning",
      "text-only",
      "graded",
      "frontier"
    ],
    "function_name": "hle_text",
    "is_alpha": false
  },
  {
    "name": "Instruction Following",
    "description": "Tests ability to follow specific formatting and content constraints with both strict and loose evaluation metrics",
    "category": "core",
    "tags": [
      "instruction-following",
      "constraints",
      "formatting"
    ],
    "function_name": "ifeval",
    "is_alpha": false
  },
  {
    "name": "JSONSchemaBench",
    "description": "JSON Schema generation benchmark with ~10K real-world schemas from GitHub, Kubernetes, and other sources for evaluating constrained decoding",
    "category": "core",
    "tags": [
      "json",
      "jsonschema",
      "generation",
      "constrained-decoding"
    ],
    "function_name": "jsonschemabench",
    "is_alpha": false
  },
  {
    "name": "LiveMCPBench",
    "description": "Benchmark for evaluating LLM agents on real-world tasks using the Model Context Protocol (MCP) - 95 tasks across different categories",
    "category": "core",
    "tags": [
      "mcp",
      "agents",
      "real-world",
      "tools",
      "graded"
    ],
    "function_name": "livemcpbench",
    "is_alpha": false
  },
  {
    "name": "MATH",
    "description": "Measuring Mathematical Problem Solving - 5000 competition math problems across 7 subjects and 5 difficulty levels",
    "category": "core",
    "tags": [
      "math",
      "problem-solving",
      "reasoning",
      "competition",
      "graded"
    ],
    "function_name": "math",
    "is_alpha": false
  },
  {
    "name": "MATH-500",
    "description": "500-problem subset of MATH dataset for faster evaluation of mathematical problem solving",
    "category": "core",
    "tags": [
      "math",
      "problem-solving",
      "reasoning",
      "competition",
      "graded",
      "subset"
    ],
    "function_name": "math_500",
    "is_alpha": false
  },
  {
    "name": "MBPP",
    "description": "Mostly Basic Python Problems — code generation tasks with unit test verification",
    "category": "core",
    "tags": [
      "code",
      "generation",
      "sandbox",
      "reasoning"
    ],
    "function_name": "mbpp",
    "is_alpha": false
  },
  {
    "name": "MGSM",
    "description": "Multilingual Grade School Math benchmark across 11 languages for testing mathematical reasoning",
    "category": "core",
    "tags": [
      "math",
      "multilingual",
      "reasoning",
      "chain-of-thought"
    ],
    "function_name": "mgsm",
    "is_alpha": false
  },
  {
    "name": "MGSM English",
    "description": "Grade school math problems in English for testing mathematical reasoning",
    "category": "core",
    "tags": [
      "math",
      "english",
      "reasoning",
      "chain-of-thought"
    ],
    "function_name": "mgsm_en",
    "is_alpha": false
  },
  {
    "name": "MGSM Latin Script",
    "description": "Grade school math problems in Latin script languages (German, English, Spanish, French, Swahili)",
    "category": "core",
    "tags": [
      "math",
      "multilingual",
      "latin-script",
      "reasoning",
      "chain-of-thought"
    ],
    "function_name": "mgsm_latin",
    "is_alpha": false
  },
  {
    "name": "MGSM Non-Latin Script",
    "description": "Grade school math problems in non-Latin script languages (Bengali, Japanese, Russian, Telugu, Thai, Chinese)",
    "category": "core",
    "tags": [
      "math",
      "multilingual",
      "non-latin-script",
      "reasoning",
      "chain-of-thought"
    ],
    "function_name": "mgsm_non_latin",
    "is_alpha": false
  },
  {
    "name": "MMLU (cais/mmlu)",
    "description": "Massive Multitask Language Understanding - 57 academic subjects from the cais/mmlu dataset. Only supports English (EN-US).",
    "category": "core",
    "tags": [
      "multiple-choice",
      "knowledge",
      "reasoning",
      "multitask"
    ],
    "function_name": "mmlu",
    "is_alpha": false
  },
  {
    "name": "MMLU Pro (TIGER-Lab)",
    "description": "Enhanced version of MMLU with more challenging, reasoning-focused questions.",
    "category": "core",
    "tags": [
      "multiple-choice",
      "knowledge",
      "reasoning",
      "multitask"
    ],
    "function_name": "mmlu_pro",
    "is_alpha": false
  },
  {
    "name": "MMMLU (openai/MMMLU)",
    "description": "MMLU translated to 15 languages.",
    "category": "core",
    "tags": [
      "multiple-choice",
      "knowledge",
      "reasoning",
      "multitask"
    ],
    "function_name": "mmmlu",
    "is_alpha": false
  },
  {
    "name": "MMMU",
    "description": "Massive Multi-discipline Multimodal Understanding and Reasoning Benchmark with 11.5K questions across 30 subjects from college exams, quizzes, and textbooks",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "reasoning",
      "college-level",
      "images"
    ],
    "function_name": "mmmu",
    "is_alpha": false
  },
  {
    "name": "MMMU Accounting",
    "description": "MMMU Accounting subset focusing on accounting principles and practices",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "accounting",
      "business",
      "images"
    ],
    "function_name": "mmmu_accounting",
    "is_alpha": false
  },
  {
    "name": "MMMU Agriculture",
    "description": "MMMU Agriculture subset focusing on agricultural sciences and practices",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "agriculture",
      "science",
      "images"
    ],
    "function_name": "mmmu_agriculture",
    "is_alpha": false
  },
  {
    "name": "MMMU Architecture and Engineering",
    "description": "MMMU Architecture and Engineering subset focusing on engineering design and architecture",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "architecture",
      "engineering",
      "design",
      "images"
    ],
    "function_name": "mmmu_architecture_and_engineering",
    "is_alpha": false
  },
  {
    "name": "MMMU Art",
    "description": "MMMU Art subset focusing on art and visual design questions",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "art",
      "visual-design",
      "images"
    ],
    "function_name": "mmmu_art",
    "is_alpha": false
  },
  {
    "name": "MMMU Art Theory",
    "description": "MMMU Art Theory subset focusing on art history and theoretical concepts",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "art",
      "theory",
      "history",
      "images"
    ],
    "function_name": "mmmu_art_theory",
    "is_alpha": false
  },
  {
    "name": "MMMU Basic Medical Science",
    "description": "MMMU Basic Medical Science subset focusing on fundamental medical knowledge",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "medicine",
      "science",
      "health",
      "images"
    ],
    "function_name": "mmmu_basic_medical_science",
    "is_alpha": false
  },
  {
    "name": "MMMU Biology",
    "description": "MMMU Biology subset focusing on biological sciences",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "biology",
      "science",
      "images"
    ],
    "function_name": "mmmu_biology",
    "is_alpha": false
  },
  {
    "name": "MMMU Chemistry",
    "description": "MMMU Chemistry subset focusing on chemical sciences",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "chemistry",
      "science",
      "images"
    ],
    "function_name": "mmmu_chemistry",
    "is_alpha": false
  },
  {
    "name": "MMMU Clinical Medicine",
    "description": "MMMU Clinical Medicine subset focusing on clinical medical practice",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "medicine",
      "clinical",
      "health",
      "images"
    ],
    "function_name": "mmmu_clinical_medicine",
    "is_alpha": false
  },
  {
    "name": "MMMU Design",
    "description": "MMMU Design subset focusing on design principles and practices",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "design",
      "visual",
      "creative",
      "images"
    ],
    "function_name": "mmmu_design",
    "is_alpha": false
  },
  {
    "name": "MMMU Diagnostics and Laboratory Medicine",
    "description": "MMMU Diagnostics and Laboratory Medicine subset focusing on medical diagnostics",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "medicine",
      "diagnostics",
      "laboratory",
      "images"
    ],
    "function_name": "mmmu_diagnostics_and_laboratory_medicine",
    "is_alpha": false
  },
  {
    "name": "MMMU Electronics",
    "description": "MMMU Electronics subset focusing on electronic systems and circuits",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "electronics",
      "engineering",
      "technology",
      "images"
    ],
    "function_name": "mmmu_electronics",
    "is_alpha": false
  },
  {
    "name": "MMMU Energy and Power",
    "description": "MMMU Energy and Power subset focusing on energy systems and power generation",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "energy",
      "power",
      "engineering",
      "images"
    ],
    "function_name": "mmmu_energy_and_power",
    "is_alpha": false
  },
  {
    "name": "MMMU Finance",
    "description": "MMMU Finance subset focusing on financial concepts and analysis",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "finance",
      "business",
      "economics",
      "images"
    ],
    "function_name": "mmmu_finance",
    "is_alpha": false
  },
  {
    "name": "MMMU Geography",
    "description": "MMMU Geography subset focusing on geographical knowledge and analysis",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "geography",
      "earth-science",
      "spatial",
      "images"
    ],
    "function_name": "mmmu_geography",
    "is_alpha": false
  },
  {
    "name": "MMMU History",
    "description": "MMMU History subset focusing on historical knowledge and analysis",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "history",
      "humanities",
      "culture",
      "images"
    ],
    "function_name": "mmmu_history",
    "is_alpha": false
  },
  {
    "name": "MMMU Literature",
    "description": "MMMU Literature subset focusing on literary analysis and knowledge",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "literature",
      "humanities",
      "language",
      "images"
    ],
    "function_name": "mmmu_literature",
    "is_alpha": false
  },
  {
    "name": "MMMU MCQ",
    "description": "MMMU MCQ subset focusing on multiple choice questions",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "images"
    ],
    "function_name": "mmmu_mcq",
    "is_alpha": false
  },
  {
    "name": "MMMU Management",
    "description": "MMMU Management subset focusing on management principles and practices",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "management",
      "business",
      "leadership",
      "images"
    ],
    "function_name": "mmmu_manage",
    "is_alpha": false
  },
  {
    "name": "MMMU Marketing",
    "description": "MMMU Marketing subset focusing on marketing strategies and concepts",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "marketing",
      "business",
      "communication",
      "images"
    ],
    "function_name": "mmmu_marketing",
    "is_alpha": false
  },
  {
    "name": "MMMU Materials",
    "description": "MMMU Materials subset focusing on materials science and engineering",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "materials",
      "science",
      "engineering",
      "images"
    ],
    "function_name": "mmmu_materials",
    "is_alpha": false
  },
  {
    "name": "MMMU Math",
    "description": "MMMU Mathematics subset focusing on mathematical reasoning",
    "category": "math",
    "tags": [
      "multimodal",
      "multiple-choice",
      "mathematics",
      "reasoning",
      "images"
    ],
    "function_name": "mmmu_math",
    "is_alpha": false
  },
  {
    "name": "MMMU Mechanical Engineering",
    "description": "MMMU Mechanical Engineering subset focusing on mechanical systems and design",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "mechanical",
      "engineering",
      "design",
      "images"
    ],
    "function_name": "mmmu_mechanical_engineering",
    "is_alpha": false
  },
  {
    "name": "MMMU Music",
    "description": "MMMU Music subset focusing on music theory and analysis",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "music",
      "arts",
      "theory",
      "images"
    ],
    "function_name": "mmmu_music",
    "is_alpha": false
  },
  {
    "name": "MMMU Open",
    "description": "MMMU Open subset focusing on open-ended questions",
    "category": "core",
    "tags": [
      "multimodal",
      "open-ended",
      "images"
    ],
    "function_name": "mmmu_open",
    "is_alpha": false
  },
  {
    "name": "MMMU Pharmacy",
    "description": "MMMU Pharmacy subset focusing on pharmaceutical sciences and practice",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "pharmacy",
      "medicine",
      "health",
      "images"
    ],
    "function_name": "mmmu_pharmacy",
    "is_alpha": false
  },
  {
    "name": "MMMU Physics",
    "description": "MMMU Physics subset focusing on physics and physical sciences",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "physics",
      "science",
      "images"
    ],
    "function_name": "mmmu_physics",
    "is_alpha": false
  },
  {
    "name": "MMMU Public Health",
    "description": "MMMU Public Health subset focusing on public health concepts and practices",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "public-health",
      "health",
      "population",
      "images"
    ],
    "function_name": "mmmu_public_health",
    "is_alpha": false
  },
  {
    "name": "MMMU Sociology",
    "description": "MMMU Sociology subset focusing on sociological concepts and analysis",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "sociology",
      "social-science",
      "society",
      "images"
    ],
    "function_name": "mmmu_sociology",
    "is_alpha": false
  },
  {
    "name": "MMMU-Pro",
    "description": "Enhanced multimodal MMMU-Pro benchmark with multiple-choice across many options and images",
    "category": "core",
    "tags": [
      "multimodal",
      "multiple-choice",
      "reasoning",
      "images",
      "mmmu-pro"
    ],
    "function_name": "mmmu_pro",
    "is_alpha": false
  },
  {
    "name": "MMMU-Pro (Vision)",
    "description": "MMMU-Pro vision subset with images and multiple-choice questions",
    "category": "core",
    "tags": [
      "multimodal",
      "vision",
      "multiple-choice",
      "images",
      "mmmu-pro"
    ],
    "function_name": "mmmu_pro_vision",
    "is_alpha": false
  },
  {
    "name": "MMStar",
    "description": "MMStar benchmark for measuring multi-modal gain and leakage via coordinated vision and text ablations",
    "category": "core",
    "tags": [
      "vision",
      "multi-modal",
      "leakage",
      "perception",
      "reasoning"
    ],
    "function_name": "mmstar",
    "is_alpha": false
  },
  {
    "name": "MedMCQA",
    "description": "Medical multiple-choice questions from Indian medical entrance exams (AIIMS & NEET PG)",
    "category": "core",
    "tags": [
      "multiple-choice",
      "medical",
      "healthcare",
      "medicine"
    ],
    "function_name": "medmcqa",
    "is_alpha": false
  },
  {
    "name": "MedQA",
    "description": "US Medical Licensing Exam (USMLE) questions for medical reasoning",
    "category": "core",
    "tags": [
      "multiple-choice",
      "medical",
      "healthcare",
      "medicine",
      "clinical"
    ],
    "function_name": "medqa",
    "is_alpha": false
  },
  {
    "name": "MuSR",
    "description": "Testing the Limits of Chain-of-thought with Multistep Soft Reasoning - includes murder mysteries, object placements, and team allocation tasks",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "commonsense",
      "chain-of-thought"
    ],
    "function_name": "musr",
    "is_alpha": false
  },
  {
    "name": "MuSR Murder Mysteries",
    "description": "MuSR murder mystery scenarios - who is the most likely murderer?",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "commonsense",
      "chain-of-thought",
      "murder-mysteries"
    ],
    "function_name": "musr_murder_mysteries",
    "is_alpha": false
  },
  {
    "name": "MuSR Object Placements",
    "description": "MuSR object placement reasoning - where would someone look for an object?",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "commonsense",
      "chain-of-thought",
      "object-placements"
    ],
    "function_name": "musr_object_placements",
    "is_alpha": false
  },
  {
    "name": "MuSR Team Allocation",
    "description": "MuSR team allocation problems - how to allocate people to tasks efficiently?",
    "category": "core",
    "tags": [
      "multiple-choice",
      "reasoning",
      "commonsense",
      "chain-of-thought",
      "team-allocation"
    ],
    "function_name": "musr_team_allocation",
    "is_alpha": false
  },
  {
    "name": "OpenAI MRCR (2 Needles)",
    "description": "Memory-Recall with Contextual Retrieval - long-context evaluation that measures recall of 2 needles across million-token contexts",
    "category": "core",
    "tags": [
      "long-context",
      "retrieval",
      "needle",
      "sequence-matching"
    ],
    "function_name": "openai_mrcr_2n",
    "is_alpha": false
  },
  {
    "name": "OpenAI MRCR (4 Needles)",
    "description": "Memory-Recall with Contextual Retrieval - long-context evaluation that measures recall of 4 needles across million-token contexts",
    "category": "core",
    "tags": [
      "long-context",
      "retrieval",
      "needle",
      "sequence-matching"
    ],
    "function_name": "openai_mrcr_4n",
    "is_alpha": false
  },
  {
    "name": "OpenAI MRCR (8 Needles)",
    "description": "Memory-Recall with Contextual Retrieval - long-context evaluation that measures recall of 8 needles across million-token contexts",
    "category": "core",
    "tags": [
      "long-context",
      "retrieval",
      "needle",
      "sequence-matching"
    ],
    "function_name": "openai_mrcr_8n",
    "is_alpha": false
  },
  {
    "name": "OpenAI MRCR (Full)",
    "description": "Memory-Recall with Contextual Retrieval - long-context evaluation that measures recall of 2, 4, and 8 needles across million-token contexts",
    "category": "core",
    "tags": [
      "long-context",
      "retrieval",
      "needle",
      "sequence-matching"
    ],
    "function_name": "openai_mrcr",
    "is_alpha": false
  },
  {
    "name": "OpenBookQA",
    "description": "Elementary-level science questions probing understanding of core facts",
    "category": "core",
    "tags": [
      "multiple-choice",
      "science",
      "elementary",
      "open-book"
    ],
    "function_name": "openbookqa",
    "is_alpha": false
  },
  {
    "name": "PubMedQA",
    "description": "Biomedical question answering from PubMed abstracts",
    "category": "core",
    "tags": [
      "multiple-choice",
      "medical",
      "biomedical",
      "research",
      "literature"
    ],
    "function_name": "pubmedqa",
    "name": "PIQA",
    "description": "Physical Interaction Question Answering - commonsense about physical situations",
    "category": "core",
    "tags": [
      "multiple-choice",
      "commonsense-reasoning",
      "physical-reasoning"
    ],
    "function_name": "piqa",
    "is_alpha": false
  },
  {
    "name": "PROST",
    "description": "Physical Reasoning about Objects through Space and Time",
    "category": "core",
    "tags": [
      "multiple-choice",
      "commonsense-reasoning",
      "physical-reasoning"
    ],
    "function_name": "prost",
    "is_alpha": false
  },
  {
    "name": "SWAG",
    "description": "Situations With Adversarial Generations - grounded commonsense inference",
    "category": "core",
    "tags": [
      "multiple-choice",
      "commonsense-reasoning",
      "video-captions"
    ],
    "function_name": "swag",
    "is_alpha": false
  },
  {
    "name": "SciCode",
    "description": "Scientific computing and programming challenges",
    "category": "core",
    "tags": [
      "code-generation",
      "science",
      "alpha"
    ],
    "function_name": "scicode",
    "is_alpha": true
  },
  {
    "name": "SimpleQA",
    "description": "Measuring short-form factuality in large language models with simple Q&A pairs",
    "category": "core",
    "tags": [
      "factuality",
      "question-answering",
      "graded"
    ],
    "function_name": "simpleqa",
    "is_alpha": false
  },
  {
    "name": "SuperGPQA",
    "description": "Scaling LLM Evaluation across 285 Graduate Disciplines - 26,529 multiple-choice questions across science, engineering, medicine, economics, and philosophy",
    "category": "core",
    "tags": [
      "multiple-choice",
      "knowledge",
      "graduate-level",
      "multidisciplinary"
    ],
    "function_name": "supergpqa",
    "is_alpha": false
  },
  {
    "name": "TUMLU",
    "description": "TUMLU is a comprehensive, multilingual, and natively developed language understanding benchmark specifically designed for Turkic languages.",
    "category": "community",
    "tags": [
      "factuality",
      "question-answering",
      "multiple-choice",
      "reasoning"
    ],
    "function_name": "tumlu",
    "is_alpha": false
  },
  {
    "name": "Terraform",
    "description": "Terraform Multiple Choice Questions",
    "category": "core",
    "tags": [
      "code-understanding"
    ],
    "function_name": "rootly_terraform",
    "is_alpha": false
  },
  {
    "name": "XCOPA (11 Languages)",
    "description": "Cross-lingual Choice of Plausible Alternatives for causal commonsense reasoning",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual"
    ],
    "function_name": "xcopa",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Chinese",
    "description": "XCOPA causal reasoning for Chinese (zh)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_zh",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Estonian",
    "description": "XCOPA causal reasoning for Estonian (et)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_et",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Haitian Creole",
    "description": "XCOPA causal reasoning for Haitian Creole (ht)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_ht",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Indonesian",
    "description": "XCOPA causal reasoning for Indonesian (id)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_id",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Italian",
    "description": "XCOPA causal reasoning for Italian (it)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_it",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Quechua",
    "description": "XCOPA causal reasoning for Quechua (qu)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_qu",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Swahili",
    "description": "XCOPA causal reasoning for Swahili (sw)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_sw",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Tamil",
    "description": "XCOPA causal reasoning for Tamil (ta)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_ta",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Thai",
    "description": "XCOPA causal reasoning for Thai (th)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_th",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Turkish",
    "description": "XCOPA causal reasoning for Turkish (tr)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_tr",
    "is_alpha": false
  },
  {
    "name": "XCOPA: Vietnamese",
    "description": "XCOPA causal reasoning for Vietnamese (vi)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "causal-reasoning",
      "commonsense",
      "multilingual",
      "xcopa"
    ],
    "function_name": "xcopa_vi",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze (11 Languages)",
    "description": "Cross-lingual story completion for commonsense reasoning",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual"
    ],
    "function_name": "xstorycloze",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: Arabic",
    "description": "XStoryCloze story completion for Arabic (ar)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_ar",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: Basque",
    "description": "XStoryCloze story completion for Basque (eu)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_eu",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: Burmese",
    "description": "XStoryCloze story completion for Burmese (my)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_my",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: Chinese",
    "description": "XStoryCloze story completion for Chinese (zh)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_zh",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: English",
    "description": "XStoryCloze story completion for English (en)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_en",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: Hindi",
    "description": "XStoryCloze story completion for Hindi (hi)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_hi",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: Indonesian",
    "description": "XStoryCloze story completion for Indonesian (id)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_id",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: Russian",
    "description": "XStoryCloze story completion for Russian (ru)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_ru",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: Spanish",
    "description": "XStoryCloze story completion for Spanish (es)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_es",
    "is_alpha": false
  },
  {
    "name": "XStoryCloze: Swahili",
    "description": "XStoryCloze story completion for Swahili (sw)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_sw",
    "is_alpha": false
  },
  {
    "name": "MultiRC",
    "description": "Multi-Sentence Reading Comprehension",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "superglue",
      "nli",
      "reasoning"
    ],
    "function_name": "multirc",
    "is_alpha": false
  },
  {
    "name": "OpenAI MRCR (2 Needles)",
    "description": "Memory-Recall with Contextual Retrieval - long-context evaluation that measures recall of 2 needles across million-token contexts",
    "category": "core",
    "name": "XStoryCloze: Telugu",
    "description": "XStoryCloze story completion for Telugu (te)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "story-completion",
      "commonsense",
      "multilingual",
      "xstorycloze"
    ],
    "function_name": "xstorycloze_te",
    "is_alpha": false
  },
  {
    "name": "XWinograd (6 Languages)",
    "description": "Cross-lingual Winograd Schema Challenge for pronoun resolution",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "pronoun-resolution",
      "commonsense",
      "multilingual"
    ],
    "function_name": "xwinograd",
    "is_alpha": false
  },
  {
    "name": "XWinograd: Chinese",
    "description": "XWinograd pronoun resolution for Chinese (zh)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "pronoun-resolution",
      "commonsense",
      "multilingual",
      "xwinograd"
    ],
    "function_name": "xwinograd_zh",
    "is_alpha": false
  },
  {
    "name": "XWinograd: English",
    "description": "XWinograd pronoun resolution for English (en)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "pronoun-resolution",
      "commonsense",
      "multilingual",
      "xwinograd"
    ],
    "function_name": "xwinograd_en",
    "is_alpha": false
  },
  {
    "name": "XWinograd: French",
    "description": "XWinograd pronoun resolution for French (fr)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "pronoun-resolution",
      "commonsense",
      "multilingual",
      "xwinograd"
    ],
    "function_name": "xwinograd_fr",
    "is_alpha": false
  },
  {
    "name": "RTE (SuperGLUE)",
    "description": "Recognizing Textual Entailment from SuperGLUE",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "superglue",
      "nli",
      "reasoning"
    ],
    "function_name": "rte_superglue",
    "is_alpha": false
  },
  {
    "name": "SciCode",
    "description": "Scientific computing and programming challenges",
    "category": "core",
    "name": "XWinograd: Japanese",
    "description": "XWinograd pronoun resolution for Japanese (jp)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "pronoun-resolution",
      "commonsense",
      "multilingual",
      "xwinograd"
    ],
    "function_name": "xwinograd_jp",
    "is_alpha": false
  },
  {
    "name": "XWinograd: Portuguese",
    "description": "XWinograd pronoun resolution for Portuguese (pt)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "pronoun-resolution",
      "commonsense",
      "multilingual",
      "xwinograd"
    ],
    "function_name": "xwinograd_pt",
    "is_alpha": false
  },
  {
    "name": "SuperGLUE (All Tasks)",
    "description": "SuperGLUE benchmark suite - run any subset by name (copa, rte, wic, wsc, cb, multirc)",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "superglue",
      "nli",
      "reasoning"
    ],
    "function_name": "superglue",
    "is_alpha": false
  },
  {
    "name": "SuperGPQA",
    "description": "Scaling LLM Evaluation across 285 Graduate Disciplines - 26,529 multiple-choice questions across science, engineering, medicine, economics, and philosophy",
    "category": "core",
    "name": "XWinograd: Russian",
    "description": "XWinograd pronoun resolution for Russian (ru)",
    "category": "cross-lingual",
    "tags": [
      "multiple-choice",
      "pronoun-resolution",
      "commonsense",
      "multilingual",
      "xwinograd"
    ],
    "function_name": "xwinograd_ru",
    "is_alpha": false
  },
  {
    "name": "WSC273",
    "description": "Original Winograd Schema Challenge with 273 expert-crafted questions",
    "category": "core",
    "tags": [
      "multiple-choice",
      "commonsense-reasoning",
      "pronoun-resolution"
    ],
    "function_name": "wsc273",
    "is_alpha": false
  },
  {
    "name": "WinoGrande",
    "description": "Large-scale Winograd Schema Challenge for commonsense pronoun resolution",
    "category": "core",
    "tags": [
      "multiple-choice",
      "commonsense-reasoning",
      "pronoun-resolution"
    ],
    "function_name": "winogrande",
    "is_alpha": false
  },
  {
    "name": "WSC",
    "description": "Winograd Schema Challenge - coreference resolution",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "superglue",
      "nli",
      "reasoning"
    ],
    "function_name": "wsc",
    "is_alpha": false
  },
  {
    "name": "WiC",
    "description": "Word in Context - word sense disambiguation",
    "category": "glue",
    "tags": [
      "multiple-choice",
      "superglue",
      "nli",
      "reasoning"
    ],
    "function_name": "wic",
    "is_alpha": false
  }
];
